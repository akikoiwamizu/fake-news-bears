{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5254936-fe0f-4382-902b-9943bb445261",
   "metadata": {},
   "source": [
    "# Get HuggingFace Roberta Hate Scoring Tranformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca189a7-da78-4204-b823-ecb8086060e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n",
      "Installing collected packages: tokenizers, regex, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.12.1 regex-2022.10.31 tokenizers-0.13.2 transformers-4.26.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "480429f0-7767-4129-aaa2-8b62966e3e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c0c755de794dddaefec9c97da9145c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/700 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f92ab4d7fd4cad9fe4ece694b00392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840a020f62824906b88cd4c77e2e904f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a961d48e71ca439abf14705db97279b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb5011af6e540ed832f3e6345dd78b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) not-hate 0.9168\n",
      "2) hate 0.0832\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='hate'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night ðŸ˜Š\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night ðŸ˜Š\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f963e-e456-435f-a09a-96e2244d1612",
   "metadata": {},
   "source": [
    "# Query BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d59e77-3eda-4c04-9df4-293ca3077af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "import google.cloud.aiplatform as vertex_ai\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba7471e-df6c-4be8-a584-87e8cd0a69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a471ae52-0b8c-4547-a3aa-1b757ab45a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to use BigQuery client to run query/job, return job ID or result as DF\n",
    "def run_bq_query(sql: str) -> Union[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Input: SQL query, as a string, to execute in BigQuery\n",
    "    Returns the query results as a pandas DataFrame, or error, if any\n",
    "    \"\"\"\n",
    "\n",
    "    # Try dry run before executing query to catch any errors\n",
    "    job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "    bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    # If dry run succeeds without errors, proceed to run query\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    client_result = bq_client.query(sql, job_config=job_config)\n",
    "\n",
    "    job_id = client_result.job_id\n",
    "\n",
    "    # Wait for query/job to finish running. then get & return data frame\n",
    "    df = client_result.result().to_arrow().to_pandas()\n",
    "    print(f\"Finished job_id: {job_id}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91da43f-769e-4554-9f3a-e7bbe824da6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job_id: e65425cf-88b7-4ff6-a39c-dfb5d8c95975\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT text FROM `fake-news-bears.usa_congress_twitter.tweets`\n",
    "WHERE text != \"\"\n",
    "LIMIT 100;\n",
    "\"\"\"\n",
    "\n",
    "my_df = run_bq_query(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aabaf2af-5da7-462a-869e-645a9ee5b785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICYMI: House Republicans Release Economic Plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy New Year! No matter the obstacles we fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inflation continues to ravage the paychecks of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy Thanksgiving to all celebrating, and a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Americans don't deserve record inflation, high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>This program is going to be a critical compone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>This threatened national and economic security...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>When Republicans took power in 2010, they defu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Insurers are required to cover mental health c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>As Americans travel for the holidays, I'm work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   ICYMI: House Republicans Release Economic Plan...\n",
       "1   Happy New Year! No matter the obstacles we fac...\n",
       "2   Inflation continues to ravage the paychecks of...\n",
       "3   Happy Thanksgiving to all celebrating, and a s...\n",
       "4   Americans don't deserve record inflation, high...\n",
       "..                                                ...\n",
       "95  This program is going to be a critical compone...\n",
       "96  This threatened national and economic security...\n",
       "97  When Republicans took power in 2010, they defu...\n",
       "98  Insurers are required to cover mental health c...\n",
       "99  As Americans travel for the holidays, I'm work...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc17a2c-8e1b-4400-a745-e5522ab9adf1",
   "metadata": {},
   "source": [
    "# Score text using model\n",
    "Given a dataframe with text, return with additional column scoring hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "047e9d1e-0753-4b52-ad8d-55887a490e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>non-hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICYMI: House Republicans Release Economic Plan...</td>\n",
       "      <td>0.940829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy New Year! No matter the obstacles we fac...</td>\n",
       "      <td>0.986421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inflation continues to ravage the paychecks of...</td>\n",
       "      <td>0.919753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy Thanksgiving to all celebrating, and a s...</td>\n",
       "      <td>0.984058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Americans don't deserve record inflation, high...</td>\n",
       "      <td>0.920001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The true impact of inflation cannot be underst...</td>\n",
       "      <td>0.960717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>border security = national security</td>\n",
       "      <td>0.941848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>energy security = national security\\n\\nborder ...</td>\n",
       "      <td>0.960721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>January 6th was a test of our Constitutional t...</td>\n",
       "      <td>0.976341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The\\u00a04,126-page, $1.8 trillion spending sp...</td>\n",
       "      <td>0.967310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  non-hate\n",
       "0  ICYMI: House Republicans Release Economic Plan...  0.940829\n",
       "1  Happy New Year! No matter the obstacles we fac...  0.986421\n",
       "2  Inflation continues to ravage the paychecks of...  0.919753\n",
       "3  Happy Thanksgiving to all celebrating, and a s...  0.984058\n",
       "4  Americans don't deserve record inflation, high...  0.920001\n",
       "5  The true impact of inflation cannot be underst...  0.960717\n",
       "6                border security = national security  0.941848\n",
       "7  energy security = national security\\n\\nborder ...  0.960721\n",
       "8  January 6th was a test of our Constitutional t...  0.976341\n",
       "9  The\\u00a04,126-page, $1.8 trillion spending sp...  0.967310"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embedding_df(dataframe):\n",
    "    encoded_series = dataframe['text'].apply(lambda x: tokenizer(x, return_tensors='pt'))\n",
    "    features = encoded_series.apply(lambda x: model(**x))\n",
    "    scores = features.apply(lambda x: x[0][0].detach().numpy())\n",
    "    scores_softmax = scores.apply(lambda x: softmax(x))\n",
    "    # https://github.com/cardiffnlp/tweeteval/blob/main/datasets/hate/mapping.txt\n",
    "    dataframe['non-hate'] = scores_softmax.apply(lambda x: x[0])\n",
    "    return dataframe\n",
    "    \n",
    "\n",
    "\n",
    "get_embedding_df(my_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fda04f27-9890-42eb-960f-55a6cdda27ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [0.7853068, 0.21469316]\n",
      "1    [0.97172135, 0.028278705]\n",
      "2     [0.89333934, 0.10666071]\n",
      "Name: text, dtype: object\n",
      "                                                text  non-hate\n",
      "0  hate. the the duck is torturing the moose. fuc...  0.785307\n",
      "1                            love. the cat is loving  0.971721\n",
      "2                             the goose does nothing  0.893339\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>non-hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hate. the the duck is torturing the moose. fuc...</td>\n",
       "      <td>0.785307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love. the cat is loving</td>\n",
       "      <td>0.971721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the goose does nothing</td>\n",
       "      <td>0.893339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  non-hate\n",
       "0  hate. the the duck is torturing the moose. fuc...  0.785307\n",
       "1                            love. the cat is loving  0.971721\n",
       "2                             the goose does nothing  0.893339"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sanity_check = pd.DataFrame({\n",
    "'text': ['hate. the the duck is torturing the moose. fuck. it wants the world to burn.', 'love. the cat is loving', 'the goose does nothing']\n",
    "})\n",
    "get_embedding_df(df_sanity_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8add58-1cc6-4600-b5c8-e5b9e8f9bab6",
   "metadata": {},
   "source": [
    "# Political Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46925e5e-c480-4001-849f-f9142163bdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e5887d71f4470e927e4fec074d403e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/643 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ccc6272ecf4072a5f0045943289f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)ncepiece.bpe.model\";:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a44540e9518481ca2e5a07c6771cc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)\"tokenizer.json\";:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8bf8222dd340d0ab84f391491a318c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244b1f0e12bf487b9bdd71d51b838615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/975 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9543a2a0f204af088878c2cec072b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)\"pytorch_model.bin\";:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "MODEL = f\"cardiffnlp/xlm-twitter-politics-sentiment\"\n",
    "\n",
    "ps_tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# PT\n",
    "ps_model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f3d0ccbb-9e21-428c-8511-b7ffb39dbfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps_get_embedding_df(dataframe):\n",
    "    encoded_series = dataframe['text'].apply(lambda x: ps_tokenizer(x, return_tensors='pt'))\n",
    "    features = encoded_series.apply(lambda x: ps_model(**x))\n",
    "    scores = features.apply(lambda x: x[0][0].detach().numpy())\n",
    "    scores_softmax = scores.apply(lambda x: softmax(x))\n",
    "    # labels mapping https://github.com/cardiffnlp/tweeteval/blob/main/datasets/sentiment/mapping.txt\n",
    "    dataframe['negative'] = scores_softmax.apply(lambda x: x[0])\n",
    "    dataframe['neutral'] = scores_softmax.apply(lambda x: x[1])\n",
    "    dataframe['positive'] = scores_softmax.apply(lambda x: x[2])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8477c33-9d20-4564-902e-df3989cf52e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n"
     ]
    }
   ],
   "source": [
    "df_political_sentiment = ps_get_embedding_df(my_df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "028b11c4-6b2a-4537-a434-d7964463e044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICYMI: House Republicans Release Economic Plan...</td>\n",
       "      <td>0.849561</td>\n",
       "      <td>0.115934</td>\n",
       "      <td>0.034505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy New Year! No matter the obstacles we fac...</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.981900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Inflation continues to ravage the paychecks of...</td>\n",
       "      <td>0.914557</td>\n",
       "      <td>0.062803</td>\n",
       "      <td>0.022640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy Thanksgiving to all celebrating, and a s...</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.016981</td>\n",
       "      <td>0.978993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Americans don't deserve record inflation, high...</td>\n",
       "      <td>0.510572</td>\n",
       "      <td>0.350333</td>\n",
       "      <td>0.139095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The true impact of inflation cannot be underst...</td>\n",
       "      <td>0.789537</td>\n",
       "      <td>0.185220</td>\n",
       "      <td>0.025243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>border security = national security</td>\n",
       "      <td>0.240088</td>\n",
       "      <td>0.353584</td>\n",
       "      <td>0.406328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>energy security = national security\\n\\nborder ...</td>\n",
       "      <td>0.168986</td>\n",
       "      <td>0.248429</td>\n",
       "      <td>0.582585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>January 6th was a test of our Constitutional t...</td>\n",
       "      <td>0.033223</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.888652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The\\u00a04,126-page, $1.8 trillion spending sp...</td>\n",
       "      <td>0.747279</td>\n",
       "      <td>0.213039</td>\n",
       "      <td>0.039683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  negative   neutral  \\\n",
       "0  ICYMI: House Republicans Release Economic Plan...  0.849561  0.115934   \n",
       "1  Happy New Year! No matter the obstacles we fac...  0.005235  0.012865   \n",
       "2  Inflation continues to ravage the paychecks of...  0.914557  0.062803   \n",
       "3  Happy Thanksgiving to all celebrating, and a s...  0.004026  0.016981   \n",
       "4  Americans don't deserve record inflation, high...  0.510572  0.350333   \n",
       "5  The true impact of inflation cannot be underst...  0.789537  0.185220   \n",
       "6                border security = national security  0.240088  0.353584   \n",
       "7  energy security = national security\\n\\nborder ...  0.168986  0.248429   \n",
       "8  January 6th was a test of our Constitutional t...  0.033223  0.078125   \n",
       "9  The\\u00a04,126-page, $1.8 trillion spending sp...  0.747279  0.213039   \n",
       "\n",
       "   positive  \n",
       "0  0.034505  \n",
       "1  0.981900  \n",
       "2  0.022640  \n",
       "3  0.978993  \n",
       "4  0.139095  \n",
       "5  0.025243  \n",
       "6  0.406328  \n",
       "7  0.582585  \n",
       "8  0.888652  \n",
       "9  0.039683  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_political_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca3f46-37e3-4cd1-9a55-b9eac57cd72f",
   "metadata": {},
   "source": [
    "# Write to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "875372e1-50f0-4964-ac84-a3cd40c0450c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished job_id: 827faf77-6641-44f4-997f-6b5062b77046\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\"\n",
    "SELECT author_id, created_at, text, id FROM `fake-news-bears.usa_congress_twitter.tweets`\n",
    "WHERE text != \"\"\n",
    "\"\"\"\n",
    "\n",
    "df_input = run_bq_query(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33340478-df90-4cbf-a062-343cc63be661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49570 entries, 0 to 49569\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   author_id   49570 non-null  int64              \n",
      " 1   created_at  49570 non-null  datetime64[ns, UTC]\n",
      " 2   text        49570 non-null  object             \n",
      " 3   id          49570 non-null  int64              \n",
      "dtypes: datetime64[ns, UTC](1), int64(2), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_input.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe402175-58b4-4f56-a8e7-62ad87daa978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002630999052865536</td>\n",
       "      <td>2023-01-25 19:16:37+00:00</td>\n",
       "      <td>ICYMI: House Republicans Release Economic Plan...</td>\n",
       "      <td>1618326996916011008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002630999052865536</td>\n",
       "      <td>2023-01-01 17:49:18+00:00</td>\n",
       "      <td>Happy New Year! No matter the obstacles we fac...</td>\n",
       "      <td>1609607710986608641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004891731</td>\n",
       "      <td>2022-12-22 15:14:48+00:00</td>\n",
       "      <td>Inflation continues to ravage the paychecks of...</td>\n",
       "      <td>1605944953095454721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id                created_at  \\\n",
       "0  1002630999052865536 2023-01-25 19:16:37+00:00   \n",
       "1  1002630999052865536 2023-01-01 17:49:18+00:00   \n",
       "2           1004891731 2022-12-22 15:14:48+00:00   \n",
       "\n",
       "                                                text                   id  \n",
       "0  ICYMI: House Republicans Release Economic Plan...  1618326996916011008  \n",
       "1  Happy New Year! No matter the obstacles we fac...  1609607710986608641  \n",
       "2  Inflation continues to ravage the paychecks of...  1605944953095454721  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6972f071-2fdb-466a-94cb-7c34de45803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Political Sentiment Scoring\n",
    "df_political_sentiment = ps_get_embedding_df(df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c2448-386b-4b54-87c1-5e690c91e603",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = \"fake-news-bears.teamwork.jyang_political_sentiment\"\n",
    "\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    # Specify a (partial) schema. All columns are always written to the\n",
    "    # table. The schema is used to assist in data type definitions.\n",
    "    schema=[\n",
    "        # Specify the type of columns whose type cannot be auto-detected. For\n",
    "        # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "        # data type is ambiguous.\n",
    "        bigquery.SchemaField(\"author_id\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"text\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        # Indexes are written if included in the schema by name.\n",
    "        # bigquery.SchemaField(\"negative\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "        # bigquery.SchemaField(\"neutral\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "        # bigquery.SchemaField(\"positive\", bigquery.enums.SqlTypeNames.FLOAT),\n",
    "    ],\n",
    "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
    "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
    "    # disposition it replaces the table with the loaded data.\n",
    "    write_disposition=\"WRITE_TRUNCATE\",\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
