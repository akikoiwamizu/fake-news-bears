<!-- Ethics Section -->
    <section id="ethics" class="bg-light-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Ethics & Limitations</h2>
                    <h3 class="section-subheading text-muted">Learn more about our product's ethical considerations and limitations.</h3>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12">
                  <!-- Tabs with Background on Card -->
                  <div class="card">
                    <div class="card-header">
                      <ul class="nav nav-tabs nav-justified" role="tablist" data-background-color="dark">
                        <li class="nav-item active">
                          <a class="nav-link" data-toggle="tab" href="#disc1" role="tab">Disclaimer</a>
                        </li>
                        <li class="nav-item">
                          <a class="nav-link" data-toggle="tab" href="#ethics1" role="tab">Ethics</a>
                        </li>
                        <li class="nav-item">
                          <a class="nav-link" data-toggle="tab" href="#limits1" role="tab">Limitations</a>
                        </li>
                        <li class="nav-item">
                          <a class="nav-link" data-toggle="tab" href="#privacy1" role="tab">Data Privacy</a>
                        </li>
                      </ul>
                    </div>
                    <div class="card-body">
                      <!-- Tab panes -->
                      <div class="tab-content text-left">
                        <div class="tab-pane active" id="disc1" role="tabpanel">
                          <p>
                              Our team’s intention for building this product is to educate social media users, but we must acknowledge that it has the potential to be used in ways that go against our mission and values. The models we use to score tweets on truthfulness and sentiment have limitations and possible biases as they are only as good as the data they were trained on. While we strive for accuracy, there are limitations to these methods, including variations in the interpretation of language and the subjective nature of determining what constitutes "fake news." Therefore, the scores should be taken as indicative rather than definitive.
                          </p>
                          <p>
                              This project aims to (1) inform Twitter users about the content that politicians are sharing on the platform and (2) inform politicians about how they might be contributing to the spread of fake news. We strongly advise our viewers to review the <strong><a href="#product">"Our Product"</a></strong> section for how to critically interpret and evaluate the results of a given politician. When in doubt, please feel free to reach out to anyone on our team and we would be happy to help.
                          </p>
                          <p>
                              It is essential to use these scores alongside other sources of information (such as <strong><a href="https://www.factcheck.org/" target="_blank" rel="noopener noreferrer">FactCheck.org</a></strong> or <strong><a href="https://www.politifact.com/" target="_blank" rel="noopener noreferrer">Politifact</a></strong>) and critical thinking to make informed decisions.
                          </p>
                        </div>
                        <div class="tab-pane" id="ethics1" role="tabpanel">
                          <p>
                              As a team, we recognize the potential impact of our work and have taken steps to ensure we review any breaches to our ethical values and principles. Some of the measures taken include:
                              <li>We used publicly available Twitter data from US politicians.</li>
                              <li>We worked to avoid any bias or discrimination in our analysis by employing rigorous statistical methods to ensure that our results are meaningful and representative.</li>
                              <li>We ensured that our project is transparent and that we provide clear disclaimers about the limitations of our methodology.</li>
                              <li>We aimed to use our project to promote greater transparency and accountability among US politicians on Twitter with the ultimate goal of improving the quality of information available to social media users.</li>
                              <li>We provide an opportunity for US politicians to benefit from the project by critically reviewing their impact on the spread of disinformation on Twitter.</li>
                          </p>
                          <p>
                              We acknowledge that our work is part of a broader societal conversation about the role of technology in democracy, and we are committed to ensuring that our project contributes to this conversation responsibly and ethically.
                          </p>
                        </div>
                        <div class="tab-pane" id="limits1" role="tabpanel">
                          <h4>Methodology Limitations</h4>
                          <p>
                              As with any data science project, there are limitations to the methodology we have used in scoring politicians based on their tweets.
                              <li>Fake news detection and sentiment analysis are not perfect, and errors can occur due to language nuances, emotions, and other factors that may be difficult to detect algorithmically.</li>
                              <li>Our scoring system relies solely on Twitter data, which may not provide a complete picture of a politician's record or views.</li>
                              <li>Our project may be subject to biases inherent in the data we used.</li>
                              <li>The project focuses on US politicians tweet content, which may not provide a complete picture of the politicians’ community and perspectives.</li>
                          </p>
                          <p>
                              While we have taken steps to ensure that our project adheres to ethical principles, we acknowledge that there may be unpredictable, unintended consequences or ethical implications that we need to consider further. We encourage users to interpret our results with these limitations in mind and to use our project as one of many sources of information when making decisions about politics and public discourse.
                          </p>
                          <h4>Model Limitations</h4>
                          <p>
                              Overall, our models present a promising start in terms of sentiment and text analysis, as well as highlight potential shortcomings and challenges to overcome in the next iterations of our models. While they overall perform strongly in detecting the negative sentiments of hate, irony, and offensiveness within tweets, there is much room for improvement when it comes to truth detection. When comparing human ratings to their equivalent model outputs, the model scores differed from their human counterparts by an average of 15% in the sentiment-based models, but a whopping 52% in the truth-based models.
                          </p>
                          <p>
                              These numerical figures should be taken with a grain of salt, however. Even between human evaluators, there was a measured difference of 3% and 17%, respectively, between different human ratings.  Thus, part of this discrepancy can be explained as the objective difficulty in rating the truthiness of many short statements (evident in the person-person score differences), while another part could potentially be chalked up to the limited body of text that is present in tweets. It appears that certain models may rely on a larger corpus of text in order to detect idiosyncrasies and false statements. As an example, consider the following tweet:
                              <br><br><img src="img/ethics/sample-tweet2.png" alt="Tweet Example" width="500" height="201">
                          </p>
                          <p>
                              All three of the truth-based models were relatively skeptical about this tweet. Even though the human evaluators were able to search and verify the truthfulness of this claim, as well as view the accompanying photo of this politician with the cited individuals, the present-day models neither process images nor digest links, so they struggled with what was essentially “proper noun soup” - i.e. many organization/individual names without much context in between for semantic processing, since this tweet is essentially just a list of entities.
                          </p>
                          <p>
                              Given the limitations of resources present during development, it is also likely that future iterations of our models would perform better than the present-date MVP presented here. Future iterations of the truth models would likely pull information present in linked text, as well as seek to understand more contextual factors in determining the truthfulness of more tweets. They may also employ more sophisticated flavors of models, such as large language models that revise and improve upon their performance given feedback (most notably, models akin to those used in OpenAI’s ChatGPT chatbot).
                          </p>
                          <p>
                              Please reach out to a member of our team if you are interested in viewing the raw model rating outputs from our human graders.
                          </p>
                        </div>
                        <div class="tab-pane" id="privacy1" role="tabpanel">
                          <p>
                              Our team has not explicitly given notice to the US politicians on Twitter regarding the use of their data for our project as this information is publicly available. Every Twitter user has consented to Twitter's <a href="https://twitter.com/en/tos" target="_blank" rel="noopener noreferrer"><strong>Terms of Service</strong></a> and <a href="https://twitter.com/en/privacy" target="_blank" rel="noopener noreferrer"><strong>Privacy Policy</strong></a>, which permits this data to be collected under these conditions. Having said that, it important to note that there is no informed consent process as these Twitter users may not understand nor accept that our project has assigned them a disinformation score using their data.
                          </p>
                          <p>
                              There is no formal process for these Twitter users to decline or “opt out” from the use of their data in our product unless the user does not publicly post content on Twitter (i.e., private or inactive account). However, if a team member is contacted, then we will immediately remove their Twitter data from our product’s data stores and Tableau Public dashboard.
                          </p>
                          <p>
                              Because our product uses publicly available data from Twitter’s API, we do not require a System of Records Notice (SORN). Our product follows Twitter’s Privacy Policy detailing the types of personally identifiable information (PII) that is allowed to be collected and stored. Thus, the only PII we have collected and stored is Twitter users’ handles and basic profile information.
                          </p>
                        </div>
                      </div>
                    </div>
                  </div>
                  <!-- End Tabs on plain Card -->
                </div>
            </div>
        </div>
    </section>
