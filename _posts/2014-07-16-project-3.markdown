---
title: Cardiff
subtitle: Tweet Sentiment Classification
layout: default
modal-id: 3
date: 2020-10-26
img: Cardiff.png
thumbnail: Cardiff_wide.png
alt: Cardiff Models
project-date: October 2020
source: TweetEval Research
source-link: https://arxiv.org/pdf/2010.12421.pdf
category: HuggingFace RoBERTa-base model
category-link: https://huggingface.co/cardiffnlp/twitter-roberta-base
description: "The Cardiff models work by first cleaning, tokenizing, and encoding the separated words of a sample of text and then passes them through various transformers. They are trained on a large unlabeled corpus and then fine-tuned to the task for where an appropriate training set exists.
<br><br>Training was done by starting with an original pre-trained Language Model (LM) and continued to train with Twitter data, keeping the original tokenizer and the same masked LM loss. For the tweet “Another illegal alien that shouldn’t be in America killed an innocent American couple! #BuildThatWall”, the models will make user mentions are anonymized and line breaks and website links are removed. After that it compares the word choices to predicting whether a tweet is hateful or not against any of two target communities: immigrants and women. The dataset of choice stems from the SemEval2019 Hateval challenge.
<br><br>Based on the number of tokens that match and the probability it chooses the label for a given task.  There are 6 tasks of hate, irony, offensive, real, joy, and anger. Each task has their own dataset that the tokens can stem from.
<br><br>We chose this model because of its ease of implementation and its transparency in process. It was easy to download the model from HuggingFace and implement it readily. This model was trained on the 60 Million tweets and then evaluated against 40,000 tweets."

---
